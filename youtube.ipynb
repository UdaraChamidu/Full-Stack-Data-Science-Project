{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPIZQEfK7G0WhdQY2vtrsWF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UdaraChamidu/Full-Stack-Data-Science-Project/blob/main/youtube.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install youtube-transcript-api"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gkol8XT3y4XL",
        "outputId": "48220807-bab9-4307-fcda-4aeec4ea367b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: youtube-transcript-api in /usr/local/lib/python3.12/dist-packages (1.2.2)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from youtube-transcript-api) (0.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from youtube-transcript-api) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->youtube-transcript-api) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->youtube-transcript-api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->youtube-transcript-api) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->youtube-transcript-api) (2025.8.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "QuL7DdLrs-_I"
      },
      "outputs": [],
      "source": [
        "import requests # api calls\n",
        "import json # CONVERT TO JSON\n",
        "import polars as pl # faster version of pandas\n",
        "from google.colab import userdata # load secreats\n",
        "\n",
        "from youtube_transcript_api import YouTubeTranscriptApi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract Process"
      ],
      "metadata": {
        "id": "BRYDBaAktn5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_key = userdata.get('my_key')\n",
        "\n",
        "# define channel ID\n",
        "channel_id = 'UCa9gErQ9AE5jT2DZLjXBIdA'\n",
        "\n",
        "# define url for API\n",
        "url = 'https://www.googleapis.com/youtube/v3/search'\n",
        "\n",
        "# initialize page token\n",
        "# this need to search the results in different different pages.\n",
        "# (search result is over one time. that time we need to go to the next page to see the result more)\n",
        "page_token = None\n",
        "\n",
        "# intialize list to store video data\n",
        "video_record_list = []"
      ],
      "metadata": {
        "id": "ODgnHia8tq2d"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getVideoRecords(response: requests.models.Response) -> list:\n",
        "    \"\"\"\n",
        "        Function to extract YouTube video data from GET request response\n",
        "    \"\"\"\n",
        "\n",
        "    video_record_list = []\n",
        "\n",
        "    for raw_item in json.loads(response.text)['items']:\n",
        "\n",
        "        # only execute for youtube videos\n",
        "        if raw_item['id']['kind'] != \"youtube#video\":\n",
        "            continue\n",
        "\n",
        "        video_record = {}\n",
        "        video_record['video_id'] = raw_item['id']['videoId']\n",
        "        video_record['datetime'] = raw_item['snippet']['publishedAt']\n",
        "        video_record['title'] = raw_item['snippet']['title']\n",
        "\n",
        "        video_record_list.append(video_record)\n",
        "\n",
        "    return video_record_list"
      ],
      "metadata": {
        "id": "aononC32vo54"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# extract video data across multiple search result pages\n",
        "while page_token != 0:\n",
        "    # define parameters for API call\n",
        "    params = {\"key\": my_key, 'channelId': channel_id, 'part': [\"snippet\",\"id\"], 'order': \"date\", 'maxResults':100, 'pageToken': page_token}\n",
        "\n",
        "    # make get request\n",
        "    response = requests.get(url, params=params)\n",
        "\n",
        "    # append video records to list\n",
        "    video_record_list += getVideoRecords(response)\n",
        "\n",
        "    try:\n",
        "        # grab next page token\n",
        "        page_token = json.loads(response.text)['nextPageToken']\n",
        "    except:\n",
        "        # if no next page token kill while loop\n",
        "        page_token = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8B3WKapuNEZ",
        "outputId": "8d31e094-38cf-4547-f99b-46e3311c0ef2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 36.4 ms, sys: 4.47 ms, total: 40.8 ms\n",
            "Wall time: 1.15 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# store data in data frame\n",
        "\n",
        "df = pl.DataFrame(video_record_list)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCykUq4awAEb",
        "outputId": "49a88b77-424f-4072-c28f-1ec277c4e61f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (5, 3)\n",
            "┌─────────────┬──────────────────────┬─────────────────────────────────┐\n",
            "│ video_id    ┆ datetime             ┆ title                           │\n",
            "│ ---         ┆ ---                  ┆ ---                             │\n",
            "│ str         ┆ str                  ┆ str                             │\n",
            "╞═════════════╪══════════════════════╪═════════════════════════════════╡\n",
            "│ QxLXhE1fxc4 ┆ 2025-08-31T08:00:23Z ┆ uv: The Fastest Way to Install… │\n",
            "│ enBm0jLXLZ4 ┆ 2025-08-24T08:00:44Z ┆ GitHub for AI Engineers (begin… │\n",
            "│ zKHSpwayPBU ┆ 2025-08-17T08:00:59Z ┆ Context Engineering Explained … │\n",
            "│ hugQUr4VwRA ┆ 2025-08-10T08:01:00Z ┆ How to Solve Problems with AI … │\n",
            "│ fAFJYbtTsC0 ┆ 2025-07-27T08:00:45Z ┆ Fine-tuning LLMs for Tool Use … │\n",
            "└─────────────┴──────────────────────┴─────────────────────────────────┘\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract the Transcript"
      ],
      "metadata": {
        "id": "DgwFXbi-wzEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text(transcript: list) -> str:\n",
        "    \"\"\"\n",
        "        Function to extract text from transcript dictionary\n",
        "    \"\"\"\n",
        "\n",
        "    # each line of the transcrip store in the dictionary\n",
        "    text_list = [transcript[i]['text'] for i in range(len(transcript))]\n",
        "    return ' '.join(text_list)"
      ],
      "metadata": {
        "id": "COVlEamUxG8T"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "transcript_text_list = []\n",
        "\n",
        "for i in range(len(df)):\n",
        "\n",
        "    # try to extract captions\n",
        "    try:\n",
        "        transcript = YouTubeTranscriptApi.get_transcript(df['video_id'][i])\n",
        "        transcript_text = extract_text(transcript)\n",
        "    # if not available set as n/a\n",
        "    except:\n",
        "        transcript_text = \"n/a\"\n",
        "\n",
        "    transcript_text_list.append(transcript_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pK7Igbq9wpJw",
        "outputId": "c62031d2-f390-446b-97e4-113ce5cd9091"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 165 µs, sys: 43 µs, total: 208 µs\n",
            "Wall time: 214 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# add transcripts to dataframe\n",
        "df = df.with_columns(pl.Series(name=\"transcript\", values=transcript_text_list))\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFrsgPraxu0M",
        "outputId": "fa13e8c8-7b22-4eb9-9d71-b95999c5e2e6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (5, 4)\n",
            "┌─────────────┬──────────────────────┬─────────────────────────────────┬────────────┐\n",
            "│ video_id    ┆ datetime             ┆ title                           ┆ transcript │\n",
            "│ ---         ┆ ---                  ┆ ---                             ┆ ---        │\n",
            "│ str         ┆ str                  ┆ str                             ┆ str        │\n",
            "╞═════════════╪══════════════════════╪═════════════════════════════════╪════════════╡\n",
            "│ QxLXhE1fxc4 ┆ 2025-08-31T08:00:23Z ┆ uv: The Fastest Way to Install… ┆ n/a        │\n",
            "│ enBm0jLXLZ4 ┆ 2025-08-24T08:00:44Z ┆ GitHub for AI Engineers (begin… ┆ n/a        │\n",
            "│ zKHSpwayPBU ┆ 2025-08-17T08:00:59Z ┆ Context Engineering Explained … ┆ n/a        │\n",
            "│ hugQUr4VwRA ┆ 2025-08-10T08:01:00Z ┆ How to Solve Problems with AI … ┆ n/a        │\n",
            "│ fAFJYbtTsC0 ┆ 2025-07-27T08:00:45Z ┆ Fine-tuning LLMs for Tool Use … ┆ n/a        │\n",
            "└─────────────┴──────────────────────┴─────────────────────────────────┴────────────┘\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transform Process"
      ],
      "metadata": {
        "id": "o8kD5JCHx2AC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "check for duplicates"
      ],
      "metadata": {
        "id": "XngIF03_7DNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# shape + unique values\n",
        "print(\"shape:\", df.shape)\n",
        "print(\"n unique rows:\", df.n_unique())\n",
        "for j in range(df.shape[1]):\n",
        "    print(\"n unique elements (\" + df.columns[j] + \"):\", df[:,j].n_unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bk3fT0jCx_H7",
        "outputId": "3bfd765a-85aa-4c86-9c4b-ec290a28cfb7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (151, 4)\n",
            "n unique rows: 151\n",
            "n unique elements (video_id): 151\n",
            "n unique elements (datetime): 151\n",
            "n unique elements (title): 151\n",
            "n unique elements (transcript): 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling special characters"
      ],
      "metadata": {
        "id": "ar_bTtvg9M-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this special characters are special for videos or the youtuber\n",
        "# for general purpose, we do not know special characters of videos. so i do not need this part."
      ],
      "metadata": {
        "id": "fg3Rmu4Z9LNq"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Process"
      ],
      "metadata": {
        "id": "6v_4Z1zR-htW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs('data', exist_ok=True)\n",
        "\n",
        "df.write_parquet(\"data/video-transcripts.parquet\")\n",
        "\n",
        "df = pl.read_parquet(\"data/video-transcripts.parquet\")\n"
      ],
      "metadata": {
        "id": "F5By6s_u-vTQ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Titles and Transcript"
      ],
      "metadata": {
        "id": "uwnu50NN-Nrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total number of title characters:\", sum(len(df['title'][i]) for i in range(len(df))))\n",
        "print(\"Total number of transcript characters:\", sum(len(df['transcript'][i]) for i in range(len(df))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibetWMc_-Lji",
        "outputId": "6e119c9d-bc35-4a88-93fa-c84f924232cb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of title characters: 7908\n",
            "Total number of transcript characters: 453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BthbW8Vq-k39"
      },
      "execution_count": 27,
      "outputs": []
    }
  ]
}